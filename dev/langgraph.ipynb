{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5698c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e5a48ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import io\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# TODO run code in venv (Docker)\n",
    "\n",
    "class CodeExecutor:\n",
    "    \"\"\"A class to execute code and capture printed output.\"\"\"\n",
    "    def __init__(self, namespace: dict):\n",
    "        self.namespace = namespace\n",
    "\n",
    "    def execute(self, code: str) -> tuple[bool, str]:\n",
    "        old_stdout = sys.stdout\n",
    "        redirected_output = io.StringIO()\n",
    "        sys.stdout = redirected_output\n",
    "\n",
    "        try:\n",
    "            exec(code, self.namespace)\n",
    "            output = redirected_output.getvalue()\n",
    "            return True, output\n",
    "        except Exception as e:\n",
    "            return False, f\"{type(e).__name__}: {e}\"\n",
    "        finally:\n",
    "            sys.stdout = old_stdout\n",
    "\n",
    "@dataclass\n",
    "class ExecuteResult:\n",
    "    success: bool\n",
    "    message: str | None\n",
    "    final_state: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "246345f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "class PydanticActionNode(BaseModel):\n",
    "    \"\"\"Schema for action node.\"\"\"\n",
    "    action_id: int = Field(..., description=\"The sequential ID of this action step, starting from 1.\")\n",
    "    description: str = Field(..., description=\"A brief, natural language description of what this code does.\")\n",
    "    code: str = Field(..., description=\"A valid, executable snippet of Python code for this action.\")\n",
    "\n",
    "class PydanticActionGraph(BaseModel):\n",
    "    \"\"\"Schema for task graph.\"\"\"\n",
    "    task_nodes: List[PydanticActionNode] = Field(default=[] , description=\"List of task nodes for the process.\")\n",
    "\n",
    "class TaskStatus(str, Enum):\n",
    "    \"\"\"Enum for task status values.\"\"\"\n",
    "    SUCCESS = \"success\"\n",
    "    FAILED = \"failed\" \n",
    "    PENDING = \"pending\"\n",
    "\n",
    "class TaskType(str, Enum):\n",
    "    \"\"\"Enum for task type values.\"\"\"\n",
    "    DATA_LOADING = \"data_loading\"\n",
    "    EXPLORATION = \"exploration\"\n",
    "    FEATURE_ENGINEERING = \"feature_engineering\"\n",
    "    MODEL_TRAINING = \"model_training\"\n",
    "    EVALUATION = \"evaluation\"\n",
    "    VISUALIZATION = \"visualization\"\n",
    "\n",
    "class ActionNode:\n",
    "    \"\"\"Represents a single executable code snippet within a task.\"\"\"\n",
    "    def __init__(self, action_id: int, code: str, description: str):\n",
    "        self.action_id = action_id\n",
    "        self.description = description\n",
    "        self.code = code\n",
    "        self.status = TaskStatus.PENDING\n",
    "        self.result = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"ActionNode(id={self.action_id}, description='{self.description}', status='{self.status.value}', code='{self.code[:30]}...')\"\n",
    "\n",
    "class ActionGraph:\n",
    "    \"\"\"Manages the sequence of actions for a single parent task.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.nodes: List[ActionNode] = []\n",
    "        self.result: ExecuteResult | None = None\n",
    "\n",
    "    def add_action(self, node: ActionNode):\n",
    "        self.nodes.append(node)\n",
    "        self.nodes.sort(key=lambda n: n.action_id)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"ActionGraph with {len(self.nodes)} actions.\"\n",
    "    \n",
    "    def execute_action_graph(self, namespace: dict):\n",
    "        executor = CodeExecutor(namespace=namespace)\n",
    "        last_message = ''\n",
    "        for current_action_node in self.nodes:\n",
    "            exec_success, result = executor.execute(current_action_node.code)\n",
    "            if not exec_success:\n",
    "                final_state = executor.namespace.get(\"agent_state\", {})\n",
    "                current_action_node.status = TaskStatus.FAILED\n",
    "                self.result = ExecuteResult(success=False, message=result, final_state=final_state)\n",
    "                return\n",
    "            current_action_node.status = TaskStatus.SUCCESS\n",
    "            last_message = result\n",
    "        \n",
    "        final_state = executor.namespace.get(\"agent_state\", {})\n",
    "        self.result = ExecuteResult(success=True, message=last_message, final_state=final_state)\n",
    "\n",
    "    def print_actions(self):\n",
    "        for action in self.nodes:\n",
    "            print(f\"  - ID: {action.action_id}\")\n",
    "            print(f\"    Description: {action.description}\")\n",
    "            print(f\"    Code: {action.code}\")\n",
    "            print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b3b28de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphlib import TopologicalSorter, CycleError\n",
    "from typing import TypedDict, List, Dict, Optional\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"A comprehensive state for a data science pipeline.\"\"\"\n",
    "    run_id: str\n",
    "    \n",
    "    raw_data_path: str\n",
    "    \n",
    "    cleaned_data_path: Optional[str]\n",
    "    model_path: Optional[str]\n",
    "    \n",
    "    evaluation_results: Optional[Dict[str, float]]\n",
    "    \n",
    "    visualization_paths: Optional[List[str]]\n",
    "\n",
    "    previously_done: str\n",
    "\n",
    "class TaskNode:\n",
    "    \"\"\"Represents a single node in the task graph.\"\"\"\n",
    "    def __init__(self, task_id: str, instruction: str, dependencies: list[str], task_type: TaskType, output: str):\n",
    "        if not isinstance(task_id, str) or not task_id:\n",
    "            raise ValueError(\"task_id must be a non-empty string.\")\n",
    "        \n",
    "        self.task_id = task_id\n",
    "        self.instruction = instruction\n",
    "        self.dependencies = dependencies\n",
    "        self.status = TaskStatus.PENDING\n",
    "        self.task_type = task_type\n",
    "        self.output = output\n",
    "        self.result: str | None = None\n",
    "        self.action_graph = ActionGraph()\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Provides a string representation for the task node.\"\"\"\n",
    "        return (f\"TaskNode(id='{self.task_id}', status='{self.status.value}', \"\n",
    "                f\"instruction='{self.instruction[:30]}...', deps={self.dependencies})\")\n",
    "\n",
    "    def generate_action_graph(self, llm: ChatOpenAI, agent_state: GraphState, tool_sets=[], additional_instruction: str = \"\" ) -> ActionGraph:\n",
    "        structured_llm = llm.with_structured_output(PydanticActionGraph)\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"You are a data science code generator. Given a task instruction, break it down into a sequence of executable Python code snippets. Assume pandas is imported as pd and the data is in a DataFrame named 'df'.\"),\n",
    "            (\"human\", \"Generate the action steps for this task: {instruction}. {additional_instruction}. Here is the Agent State where you can find information needed: {agent_state}\")\n",
    "        ])\n",
    "        chain = prompt | structured_llm\n",
    "        \n",
    "        pydantic_action_graph: PydanticActionGraph = chain.invoke({\"instruction\": self.instruction, \"additional_instruction\":additional_instruction, \"agent_state\":agent_state}) # type: ignore\n",
    "        \n",
    "        action_graph = ActionGraph()\n",
    "        for p_node in pydantic_action_graph.task_nodes:\n",
    "            action_node = ActionNode(\n",
    "                action_id=p_node.action_id,\n",
    "                description=p_node.description,\n",
    "                code=p_node.code\n",
    "            )\n",
    "            action_graph.add_action(action_node)\n",
    "        return action_graph\n",
    "\n",
    "    def refine_and_update_action_graph(self, llm: ChatOpenAI, agent_state: GraphState):\n",
    "        refined_graph: ActionGraph = self.generate_action_graph(llm=llm, agent_state=agent_state, additional_instruction=f\"A few errors were encountered when running the actions one-by-one. You need to debug the code using the error message: {self.action_graph.result}\")\n",
    "        self.action_graph.nodes = refined_graph.nodes\n",
    "        self.action_graph.result = None\n",
    "\n",
    "    def iterate_refining(self, llm: ChatOpenAI, agent_state: GraphState):\n",
    "        \"\"\"Generate and refine the ActionGraph within a trial limit.\"\"\"\n",
    "        current_state: GraphState = agent_state\n",
    "        \n",
    "        max_retries = 3\n",
    "        action_graph: ActionGraph = self.generate_action_graph(llm=llm, agent_state=current_state)\n",
    "        self.action_graph = action_graph\n",
    "        for _ in range(max_retries):\n",
    "            namespace = {\"agent_state\": current_state}\n",
    "            self.action_graph.execute_action_graph(namespace)\n",
    "            if self.action_graph.result is None:\n",
    "                raise Exception(\"Action Graph Result is None\")\n",
    "            if self.action_graph.result.success is False:\n",
    "                self.refine_and_update_action_graph(llm=llm, agent_state=current_state)\n",
    "            else:\n",
    "                self.status = TaskStatus.SUCCESS\n",
    "                break\n",
    "        if self.action_graph.result is not None and self.action_graph.result.success is False:\n",
    "            self.status = TaskStatus.FAILED\n",
    "            self.result = str(self.action_graph.result)\n",
    "\n",
    "    def run_action_graph(self, llm: ChatOpenAI, agent_state: GraphState) -> GraphState:\n",
    "        current_state: GraphState = agent_state\n",
    "        namespace = {\"agent_state\": current_state}\n",
    "        self.action_graph.execute_action_graph(namespace)\n",
    "        if self.action_graph.result and self.action_graph.result.final_state:\n",
    "            return self.action_graph.result.final_state # type: ignore\n",
    "        else:\n",
    "            raise RuntimeError(f'Failed to run ActionGraph {self.task_id}: {self.action_graph.result}')\n",
    "\n",
    "class TaskGraph:\n",
    "    \"\"\"Manages the entire Directed Acyclic Graph (DAG) of tasks.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.nodes: dict[str, TaskNode] = {}\n",
    "\n",
    "    def add_task(self, task: TaskNode, replace: bool = False):\n",
    "        \"\"\"Adds a TaskNode to the graph.\n",
    "        If a task with the same id exists:\n",
    "          - if replace is True, overwrite the existing TaskNode,\n",
    "          - otherwise raise ValueError.\n",
    "        \"\"\"\n",
    "        if not isinstance(task.task_id, str) or not task.task_id:\n",
    "            raise ValueError(\"task_id must be a non-empty string.\")\n",
    "        if task.task_id in self.nodes:\n",
    "            if replace:\n",
    "                self.nodes[task.task_id] = task\n",
    "                print(f\"Replaced existing Task with id '{task.task_id}'.\")\n",
    "                return\n",
    "            raise ValueError(f\"Task with id '{task.task_id}' already exists. Pass replace=True to overwrite.\")\n",
    "        self.nodes[task.task_id] = task\n",
    "\n",
    "    def get_execution_order(self) -> list[str]:\n",
    "        \"\"\"\n",
    "        Determines the execution order of tasks using topological sort.\n",
    "        This is crucial for executing tasks in the correct sequence based on their dependencies.\n",
    "        \"\"\"\n",
    "        graph_representation = {\n",
    "            task_id: node.dependencies for task_id, node in self.nodes.items()\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            ts = TopologicalSorter(graph_representation)\n",
    "            return list(ts.static_order())\n",
    "        except CycleError as e:\n",
    "            print(f\"Error: A cycle was detected in the task graph. Cannot determine execution order. Details: {e}\")\n",
    "            return []\n",
    "\n",
    "    def print_graph(self, verbose: bool = False):\n",
    "        \"\"\"Prints a summary of all tasks and their dependencies.\"\"\"\n",
    "        if not self.nodes:\n",
    "            print(\"Graph is empty.\")\n",
    "            return\n",
    "        \n",
    "        if verbose:\n",
    "            try:\n",
    "                with open(\"action-graph-codes\", \"w\", encoding=\"utf-8\") as f:\n",
    "                    for task_id, node in self.nodes.items():\n",
    "                        print(f\"  - ID: {task_id}, Status: {node.status.value}\")\n",
    "                        print(f\"    Instruction: {node.instruction}\")\n",
    "                        print(f\"    Dependencies: {node.dependencies or 'None'}\")\n",
    "                        f.write(f\"--- Task {task_id} ---\\n\")\n",
    "                        f.write(f\"Instruction: {node.instruction}\\n\")\n",
    "                        # if node has an action_graph, write each action's code\n",
    "                        if getattr(node, 'action_graph', None) and node.action_graph.nodes:\n",
    "                            for action in node.action_graph.nodes:\n",
    "                                f.write(f\"# Action {action.action_id}: {action.description}\\n\")\n",
    "                                f.write(action.code + \"\\n\\n\")\n",
    "                        else:\n",
    "                            f.write(\"# No action graph available\\n\\n\")\n",
    "                print(\"Saved action graphs codes to 'action-graph-codes'\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to write action graphs to file: {e}\")\n",
    "        \n",
    "        else:\n",
    "            print(\"--- Task Graph ---\")\n",
    "            for task_id, node in self.nodes.items():\n",
    "                print(f\"  - ID: {task_id}, Status: {node.status.value}\")\n",
    "                print(f\"    Instruction: {node.instruction}\")\n",
    "                print(f\"    Dependencies: {node.dependencies or 'None'}\")\n",
    "            print(\"--------------------\")\n",
    "\n",
    "    def run_workflow(self, llm: ChatOpenAI, agent_state: GraphState, stop_on_failure: bool = True) -> GraphState:\n",
    "        \"\"\"\n",
    "        Run tasks in topological order. For each TaskNode:\n",
    "          - evaluate optional `condition` (simple eval with limited globals),\n",
    "          - execute via TaskNode.iterate_refining(llm, agent_state),\n",
    "          - update agent_state from action_graph result if present.\n",
    "        Returns final agent_state dict.\n",
    "        \"\"\"\n",
    "        # ensure order\n",
    "        order = self.get_execution_order()\n",
    "        if not order:\n",
    "            print(\"No execution order (empty graph or cycle detected).\")\n",
    "            return agent_state\n",
    "\n",
    "        current_state = agent_state\n",
    "\n",
    "        for tid in order:\n",
    "            if tid not in self.nodes:\n",
    "                print(f\"Skipping unknown task id {tid}\")\n",
    "                continue\n",
    "\n",
    "            node = self.nodes[tid]\n",
    "            print(f\"== Running task {tid}\")\n",
    "\n",
    "            # evaluate optional condition in a minimal sandbox\n",
    "            # if getattr(node, \"condition\", None):\n",
    "            #     cond_expr = node.condition\n",
    "            #     try:\n",
    "            #         # limited eval: only agent_state provided\n",
    "            #         cond_ok = bool(eval(cond_expr, {\"__builtins__\": {}}, {\"agent_state\": agent_state}))\n",
    "            #     except Exception as e:\n",
    "            #         print(f\"Condition eval error for task {tid}: {e} -> skipping\")\n",
    "            #         cond_ok = False\n",
    "            #     if not cond_ok:\n",
    "            #         print(f\"Condition false for task {tid}; marking as skipped.\")\n",
    "            #         node.status = TaskStatus.SUCCESS\n",
    "            #         continue\n",
    "\n",
    "            # prepare namespace for execution (TaskNode expects GraphState)\n",
    "            \n",
    "            try:\n",
    "                current_state = node.run_action_graph(llm=llm, agent_state=current_state)\n",
    "            except Exception as e:\n",
    "                print(f\"Exception when running task {tid}: {type(e).__name__}: {e}\")\n",
    "                node.status = TaskStatus.FAILED\n",
    "                if stop_on_failure:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            if node.status == TaskStatus.FAILED and stop_on_failure:\n",
    "                print(\"Stopping workflow due to failure.\")\n",
    "                break\n",
    "\n",
    "        return current_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3e6c2494",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from typing import List, Any, Set, Dict\n",
    "\n",
    "class PydanticTaskNode(BaseModel):\n",
    "    \"\"\"Schema for task node.\"\"\"\n",
    "    task_id: str = Field(..., description=\"Unique id for the task node in number, e.g. 1, 2, 3 etc\")\n",
    "    dependencies: List[str] = Field(..., description=\"A list of unique ids of nodes must be completed before this.\")\n",
    "    instruction: str = Field(..., description=\"A concise instruction for the task node.\")\n",
    "    task_type: TaskType = Field(description=\"Current status of the task\")\n",
    "    output: str = Field(..., description=\"description of what data or model is produced.\")\n",
    "\n",
    "    # produces: List[str] = Field(default_factory=list, description=\"Named artifacts produced by this task (e.g. cleaned.csv, model.pkl).\")\n",
    "    # consumes: List[str] = Field(default_factory=list, description=\"Named artifacts consumed by this task.\")\n",
    "    # condition: Optional[str] = Field(None, description=\"Optional condition expression (evaluated at runtime) to decide whether to run this task.\")\n",
    "    # parallelizable: bool = Field(True, description=\"Whether this task can be run in parallel with other independent tasks.\")\n",
    "    # retry_policy: Optional[Dict[str, Any]] = Field(None, description=\"Retry policy, e.g. {'max_retries': 3, 'backoff': 'exponential'}\")\n",
    "    \n",
    "class PydanticTaskGraph(BaseModel):\n",
    "    \"\"\"Schema for task graph.\"\"\"\n",
    "    task_nodes: List[PydanticTaskNode] = Field(..., description=\"List of task nodes for the process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef29361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# --- SETUP PHASE ---\n",
    "\n",
    "# 1. Instantiate your LLM\n",
    "# llm = ChatOpenAI(...) \n",
    "\n",
    "# 2. Create your TaskNode objects based on your plan\n",
    "# This plan could also come from an initial LLM call\n",
    "task_a = TaskNode(task_id=\"A\", instruction=\"Load data from 'data.csv'\", dependencies=[], ...)\n",
    "task_b = TaskNode(task_id=\"B\", instruction=\"Clean the data, remove nulls\", dependencies=[\"A\"], ...)\n",
    "task_c = TaskNode(task_id=\"C\", instruction=\"Generate a summary plot\", dependencies=[\"B\"], ...)\n",
    "task_d = TaskNode(task_id=\"D\", instruction=\"Analyze the cleaned data\", dependencies=[\"B\"], ...)\n",
    "\n",
    "all_tasks = {\"A\": task_a, \"B\": task_b, \"C\": task_c, \"D\": task_d}\n",
    "\n",
    "# --- GRAPH ASSEMBLY ---\n",
    "\n",
    "workflow = StateGraph(MainGraphState)\n",
    "\n",
    "# 3. Add a node for each task using the generic executor\n",
    "for task_id in all_tasks.keys():\n",
    "    # Use functools.partial to create a unique function for each node\n",
    "    # that has the task_id \"baked in\".\n",
    "    node_function = partial(task_executor_node, task_id=task_id)\n",
    "    workflow.add_node(task_id, node_function)\n",
    "\n",
    "# 4. Add the central router\n",
    "workflow.add_node(\"router\", task_router)\n",
    "\n",
    "# 5. Define the workflow logic\n",
    "workflow.set_entry_point(\"router\")\n",
    "\n",
    "# After any task node finishes, it goes back to the router to decide what's next\n",
    "for task_id in all_tasks.keys():\n",
    "    workflow.add_edge(task_id, \"router\")\n",
    "\n",
    "# The router decides which task node to run. This is a conditional edge.\n",
    "workflow.add_conditional_edges(\n",
    "    \"router\",\n",
    "    # The router's output (a task_id or list of task_ids) directly maps to the node to run\n",
    "    lambda x: x,\n",
    "    # The mapping is just an identity function because the router's output is the node name\n",
    "    {task_id: task_id for task_id in all_tasks.keys()}\n",
    ")\n",
    "\n",
    "\n",
    "# --- COMPILE AND RUN ---\n",
    "\n",
    "# 6. Compile the graph\n",
    "main_graph = workflow.compile()\n",
    "\n",
    "# 7. Invoke with the initial state\n",
    "initial_state = {\"tasks\": all_tasks}\n",
    "final_state = main_graph.invoke(initial_state)\n",
    "\n",
    "print(\"\\n--- FINAL TASK STATUS ---\")\n",
    "for task_id, task in final_state['tasks'].items():\n",
    "    print(f\"Task '{task_id}': {task.status.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd236009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_task_node(task_graph: TaskGraph) -> TaskNode | None:\n",
    "    \"\"\"\n",
    "    Select a task node with PENDING status from the task graph.\n",
    "    Returns the first pending task found, or None if no pending tasks exist.\n",
    "    \"\"\"\n",
    "    for task in task_graph.nodes.values():\n",
    "        if task == TaskStatus.PENDING:\n",
    "            return task\n",
    "    \n",
    "    return None\n",
    "\n",
    "def is_graph_finished(task_graph: TaskGraph) -> bool:\n",
    "    \"\"\"\n",
    "    Checks if there is any pending nodes in graph.\n",
    "    Returns boolean value to indicate the graph condition.\n",
    "    \"\"\"\n",
    "    for task in task_graph.nodes.values():\n",
    "        if task.status == TaskStatus.PENDING:\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "92e8c68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MasterAgent:\n",
    "    def __init__(self, model:str, tools=[], max_retries:int = 3):\n",
    "\n",
    "        self.max_retries = max_retries\n",
    "        self.llm = ChatOpenAI(\n",
    "            model=model,\n",
    "            temperature=0,\n",
    "            max_completion_tokens=None,\n",
    "            timeout=None,\n",
    "            max_retries=2,\n",
    "          )\n",
    "        \n",
    "        self.tools = tools\n",
    "        self.task_graph: TaskGraph = TaskGraph()\n",
    "    \n",
    "    def _generate_task_graph(self, human_input:str):\n",
    "        \"\"\"Generates a task graph\"\"\"\n",
    "        structured_llm = self.llm.with_structured_output(PydanticTaskGraph)\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", \"You are a data science planner. Given a project description, decompose it into a sequence of data science tasks. Respond with a complete graph of all tasks required. The agents are allowed to access the data in directory '/data' and store/retrieve models in directory '/models'. All the agents will be provided the global AgentState which will store the messages from previous agent\"),\n",
    "                (\"human\", \"{input}\"),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        chain = prompt | structured_llm\n",
    "        \n",
    "        pydantic_response: PydanticTaskGraph = chain.invoke({\"input\": human_input}) # type: ignore\n",
    "        \n",
    "        for pydantic_node in pydantic_response.task_nodes:\n",
    "            node_data = pydantic_node.model_dump()\n",
    "            node = TaskNode(\n",
    "                task_id=node_data[\"task_id\"], \n",
    "                instruction=node_data[\"instruction\"], \n",
    "                dependencies=node_data[\"dependencies\"], \n",
    "                task_type=node_data[\"task_type\"],\n",
    "                output=node_data[\"output\"]\n",
    "            )\n",
    "            self.task_graph.add_task(node)\n",
    "\n",
    "        print(f'Task Graph created with {len(pydantic_response.task_nodes)} Nodes.')\n",
    "\n",
    "    def _refine_and_update_task_graph(self, add_instructions:str):\n",
    "        raise RuntimeError(f'failed to run Task Graph: {add_instructions}')\n",
    "\n",
    "    def initialize_and_populate_task_graph(self, human_input:str):\n",
    "        state_dict = {'run_id':'1', 'raw_data_path':'data/data.csv', 'previously_done':''}\n",
    "        test_state: GraphState = state_dict # type: ignore\n",
    "        self._generate_task_graph(human_input=human_input)\n",
    "        for node in self.task_graph.nodes.values():\n",
    "            node.iterate_refining(llm=self.llm, agent_state=test_state)\n",
    "            if node.status is TaskStatus.FAILED:\n",
    "                print(f'Iterate refining for Task Node {node.task_id} failed to run in limit {self.max_retries}: {node.action_graph.result}')\n",
    "                self._refine_and_update_task_graph(node.result or '')\n",
    "\n",
    "    def process_requirement(self, human_input:str, run_id:str) -> GraphState:\n",
    "        state_dict = {'run_id':run_id, 'raw_data_path':'data/data.csv', 'previously_done':''}\n",
    "        state: GraphState = state_dict # type: ignore\n",
    "\n",
    "        for node in self.task_graph.nodes.values():\n",
    "            node.iterate_refining(llm=self.llm, agent_state=state)\n",
    "            if node.status is TaskStatus.FAILED:\n",
    "                raise RuntimeError(f'Error during iteration: {node.action_graph.result}')\n",
    "\n",
    "        final_state = self.task_graph.run_workflow(llm=self.llm, agent_state=state)\n",
    "        return final_state\n",
    "\n",
    "\n",
    "master_agent = MasterAgent(model=\"gpt-5-mini-2025-08-07\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b02d806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Graph created with 2 Nodes.\n",
      "  - ID: 1, Status: success\n",
      "    Instruction: Generate a small ActionGraph (at most 3 Nodes) that: (a) load raw data from /data, (b) run quick integrity checks (missing values, types, duplicates), (c) produce a brief summary report and save an interim cleaned CSV. Return only the ActionGraph with ≤3 nodes.\n",
      "    Dependencies: None\n",
      "  - ID: 2, Status: pending\n",
      "    Instruction: Generate a small ActionGraph (at most 3 Nodes) that: (a) apply detailed cleaning rules to interim CSV (impute/drop, correct types, normalize), (b) run validation checks/unit tests on cleaned data, (c) save final cleaned dataset. Return only the ActionGraph with ≤3 nodes.\n",
      "    Dependencies: ['1']\n",
      "Saved action graphs codes to 'action-graph-codes'\n",
      "== Running task 1\n",
      "== Running task 2\n"
     ]
    }
   ],
   "source": [
    "master_agent.initialize_and_populate_task_graph(human_input=\"I need to clean up this data. Make the task short with maximum 2 Nodes and each node should have instruction to generate only small ActionGraph with at most 3 Nodes.\")\n",
    "master_agent.task_graph.print_graph(verbose=True)\n",
    "print('=== Processing Requirement with Optimized TaskGraph')\n",
    "\n",
    "final_state = master_agent.process_requirement(human_input='', run_id='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a10fe55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'run_id': '1', 'raw_data_path': 'data/data.csv', 'previously_done': ''}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83c57db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "# Data for the DataFrame\n",
    "data = {\n",
    "    'passenger_id': [1, 2, 3, 4, 5, 6],\n",
    "    'name': ['Owen Harris', 'Florence Briggs', 'Laina Heikkinen', 'Jacques Heath', 'William Allen', 'James Moran'],\n",
    "    'age': [22, 38, 26, 35, 35, np.nan],\n",
    "    'cabin': ['C85', np.nan, 'C123', 'E46', 'D', np.nan],\n",
    "    'fare': [7.25, 71.28, 7.92, 53.1, 8.05, 8.46]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "info_buffer = io.StringIO()\n",
    "\n",
    "with redirect_stdout(info_buffer):\n",
    "    df.info()\n",
    "\n",
    "df_info_string = info_buffer.getvalue()\n",
    "context = {\n",
    "    \"df_info\": df_info_string\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113255f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Graph Generated with 7 steps.\n",
      "Error when running action graph\n",
      "ExecuteResult(success=False, message=\"NameError: name 'pd' is not defined\", final_state={'run_id': '1', 'raw_data_path': 'data.csv', 'previously_done': '', 'next_step': 'clean data'})\n",
      "Action Graph Generated with 5 steps.\n",
      "  - ID: 1\n",
      "    Description: Import required libraries and initialize the AgentState (fixes the NameError for 'pd').\n",
      "    Code: import pandas as pd\n",
      "import os\n",
      "\n",
      "# Initialize or load the AgentState provided in the prompt\n",
      "agent_state = {'run_id': '1', 'raw_data_path': 'data.csv', 'previously_done': '', 'next_step': 'clean data'}\n",
      "\n",
      "print('Agent state initialized:', agent_state)\n",
      "--------------------\n",
      "  - ID: 2\n",
      "    Description: Load the raw CSV from the path in AgentState into a DataFrame named df.\n",
      "    Code: raw_path = agent_state.get('raw_data_path')\n",
      "if not raw_path:\n",
      "    raise ValueError('raw_data_path not found in agent_state')\n",
      "\n",
      "# Read the CSV into df\n",
      "df = pd.read_csv(raw_path)\n",
      "print(f'Loaded data from {raw_path} with shape', df.shape)\n",
      "--------------------\n",
      "  - ID: 3\n",
      "    Description: Fill missing values in the 'age' column with the median age (if the column exists).\n",
      "    Code: if 'age' in df.columns:\n",
      "    median_age = df['age'].median()\n",
      "    df['age'] = df['age'].fillna(median_age)\n",
      "    print(f\"Filled missing 'age' values with median: {median_age}\")\n",
      "else:\n",
      "    print(\"Warning: 'age' column not found in the DataFrame; no imputation performed.\")\n",
      "--------------------\n",
      "  - ID: 4\n",
      "    Description: Drop the 'cabin' column if it exists (safe to run even if column is absent).\n",
      "    Code: if 'cabin' in df.columns:\n",
      "    df = df.drop(columns=['cabin'])\n",
      "    print(\"Dropped 'cabin' column\")\n",
      "else:\n",
      "    print(\"'cabin' column not present; nothing to drop\")\n",
      "--------------------\n",
      "  - ID: 5\n",
      "    Description: Save the cleaned DataFrame to cleaned_data.csv and update the AgentState with the path to the result.\n",
      "    Code: cleaned_path = 'cleaned_data.csv'\n",
      "# Save cleaned data\n",
      "df.to_csv(cleaned_path, index=False)\n",
      "\n",
      "# Update AgentState so others can access the result\n",
      "agent_state['cleaned_data_path'] = cleaned_path\n",
      "# Optionally mark this step as done\n",
      "prev = agent_state.get('previously_done', '')\n",
      "if prev:\n",
      "    agent_state['previously_done'] = prev + ';cleaned data'\n",
      "else:\n",
      "    agent_state['previously_done'] = 'cleaned data'\n",
      "\n",
      "print(f\"Saved cleaned data to {cleaned_path}\")\n",
      "print('Updated agent_state:', agent_state)\n",
      "--------------------\n",
      "Execute success\n",
      "  - ID: 1\n",
      "    Description: Import required libraries and initialize the AgentState (fixes the NameError for 'pd').\n",
      "    Code: import pandas as pd\n",
      "import os\n",
      "\n",
      "# Initialize or load the AgentState provided in the prompt\n",
      "agent_state = {'run_id': '1', 'raw_data_path': 'data.csv', 'previously_done': '', 'next_step': 'clean data'}\n",
      "\n",
      "print('Agent state initialized:', agent_state)\n",
      "--------------------\n",
      "  - ID: 2\n",
      "    Description: Load the raw CSV from the path in AgentState into a DataFrame named df.\n",
      "    Code: raw_path = agent_state.get('raw_data_path')\n",
      "if not raw_path:\n",
      "    raise ValueError('raw_data_path not found in agent_state')\n",
      "\n",
      "# Read the CSV into df\n",
      "df = pd.read_csv(raw_path)\n",
      "print(f'Loaded data from {raw_path} with shape', df.shape)\n",
      "--------------------\n",
      "  - ID: 3\n",
      "    Description: Fill missing values in the 'age' column with the median age (if the column exists).\n",
      "    Code: if 'age' in df.columns:\n",
      "    median_age = df['age'].median()\n",
      "    df['age'] = df['age'].fillna(median_age)\n",
      "    print(f\"Filled missing 'age' values with median: {median_age}\")\n",
      "else:\n",
      "    print(\"Warning: 'age' column not found in the DataFrame; no imputation performed.\")\n",
      "--------------------\n",
      "  - ID: 4\n",
      "    Description: Drop the 'cabin' column if it exists (safe to run even if column is absent).\n",
      "    Code: if 'cabin' in df.columns:\n",
      "    df = df.drop(columns=['cabin'])\n",
      "    print(\"Dropped 'cabin' column\")\n",
      "else:\n",
      "    print(\"'cabin' column not present; nothing to drop\")\n",
      "--------------------\n",
      "  - ID: 5\n",
      "    Description: Save the cleaned DataFrame to cleaned_data.csv and update the AgentState with the path to the result.\n",
      "    Code: cleaned_path = 'cleaned_data.csv'\n",
      "# Save cleaned data\n",
      "df.to_csv(cleaned_path, index=False)\n",
      "\n",
      "# Update AgentState so others can access the result\n",
      "agent_state['cleaned_data_path'] = cleaned_path\n",
      "# Optionally mark this step as done\n",
      "prev = agent_state.get('previously_done', '')\n",
      "if prev:\n",
      "    agent_state['previously_done'] = prev + ';cleaned data'\n",
      "else:\n",
      "    agent_state['previously_done'] = 'cleaned data'\n",
      "\n",
      "print(f\"Saved cleaned data to {cleaned_path}\")\n",
      "print('Updated agent_state:', agent_state)\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "state_dict = {'run_id':'1', 'raw_data_path':'data.csv', 'previously_done':'', 'next_step':'clean data'}\n",
    "state: GraphState = state_dict # type: ignore\n",
    "\n",
    "my_task = TaskNode(\n",
    "    task_id=\"2\",\n",
    "    instruction=f\"Perform data cleaning: fill missing age values with the median age and drop the 'cabin' column. Save the cleaned data as cleaned_data.csv. You will have access to the universal AgentState {state} which has structure {GraphState}. Save the path to result in the AgentState for others to access.\",\n",
    "    dependencies=[\"1\"],\n",
    "    task_type=TaskType.EXPLORATION,\n",
    "    output=\"cleaned dataframe\"\n",
    ")\n",
    "\n",
    "my_task.iterate_refining(llm=llm, agent_state=state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a149c305",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
