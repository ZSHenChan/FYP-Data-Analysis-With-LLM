{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f5698c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4e5a48ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import io\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# TODO run code in venv (Docker)\n",
    "\n",
    "class CodeExecutor:\n",
    "    \"\"\"A class to execute code and capture printed output.\"\"\"\n",
    "    def __init__(self, namespace: dict):\n",
    "        self.namespace = namespace\n",
    "\n",
    "    def execute(self, code: str) -> tuple[bool, str]:\n",
    "        old_stdout = sys.stdout\n",
    "        redirected_output = io.StringIO()\n",
    "        sys.stdout = redirected_output\n",
    "\n",
    "        try:\n",
    "            exec(code, self.namespace)\n",
    "            output = redirected_output.getvalue()\n",
    "            return True, output\n",
    "        except Exception as e:\n",
    "            return False, f\"{type(e).__name__}: {e}\"\n",
    "        finally:\n",
    "            sys.stdout = old_stdout\n",
    "\n",
    "@dataclass\n",
    "class ExecuteResult:\n",
    "    success: bool\n",
    "    message: str | None\n",
    "    final_state: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "246345f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "class PydanticActionNode(BaseModel):\n",
    "    \"\"\"Schema for action node.\"\"\"\n",
    "    action_id: int = Field(..., description=\"The sequential ID of this action step, starting from 1.\")\n",
    "    description: str = Field(..., description=\"A brief, natural language description of what this code does.\")\n",
    "    code: str = Field(..., description=\"A valid, executable snippet of Python code for this action.\")\n",
    "\n",
    "class PydanticActionGraph(BaseModel):\n",
    "    \"\"\"Schema for task graph.\"\"\"\n",
    "    task_nodes: List[PydanticActionNode] = Field(default=[] , description=\"List of task nodes for the process.\")\n",
    "\n",
    "class TaskStatus(str, Enum):\n",
    "    \"\"\"Enum for task status values.\"\"\"\n",
    "    SUCCESS = \"success\"\n",
    "    FAILED = \"failed\" \n",
    "    PENDING = \"pending\"\n",
    "\n",
    "class TaskType(str, Enum):\n",
    "    \"\"\"Enum for task type values.\"\"\"\n",
    "    DATA_LOADING = \"data_loading\"\n",
    "    EXPLORATION = \"exploration\"\n",
    "    FEATURE_ENGINEERING = \"feature_engineering\"\n",
    "    MODEL_TRAINING = \"model_training\"\n",
    "    EVALUATION = \"evaluation\"\n",
    "    VISUALIZATION = \"visualization\"\n",
    "\n",
    "class ActionNode:\n",
    "    \"\"\"Represents a single executable code snippet within a task.\"\"\"\n",
    "    def __init__(self, action_id: int, code: str, description: str):\n",
    "        self.action_id = action_id\n",
    "        self.description = description\n",
    "        self.code = code\n",
    "        self.status = TaskStatus.PENDING\n",
    "        self.result = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"ActionNode(id={self.action_id}, description='{self.description}', status='{self.status.value}', code='{self.code[:30]}...')\"\n",
    "\n",
    "class ActionGraph:\n",
    "    \"\"\"Manages the sequence of actions for a single parent task.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.nodes: List[ActionNode] = []\n",
    "        self.result: ExecuteResult | None = None\n",
    "\n",
    "    def add_action(self, node: ActionNode):\n",
    "        self.nodes.append(node)\n",
    "        self.nodes.sort(key=lambda n: n.action_id)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"ActionGraph with {len(self.nodes)} actions.\"\n",
    "    \n",
    "    def execute_action_graph(self, namespace: dict):\n",
    "        executor = CodeExecutor(namespace=namespace)\n",
    "        last_message = ''\n",
    "        for current_action_node in self.nodes:\n",
    "            exec_success, result = executor.execute(current_action_node.code)\n",
    "            if not exec_success:\n",
    "                final_state = executor.namespace.get(\"agent_state\", {})\n",
    "                current_action_node.status = TaskStatus.FAILED\n",
    "                self.result = ExecuteResult(success=False, message=result, final_state=final_state)\n",
    "                return\n",
    "            current_action_node.status = TaskStatus.SUCCESS\n",
    "            last_message = result\n",
    "        \n",
    "        final_state = executor.namespace.get(\"agent_state\", {})\n",
    "        self.result = ExecuteResult(success=True, message=last_message, final_state=final_state)\n",
    "\n",
    "    def print_actions(self):\n",
    "        for action in self.nodes:\n",
    "            print(f\"  - ID: {action.action_id}\")\n",
    "            print(f\"    Description: {action.description}\")\n",
    "            print(f\"    Code: {action.code}\")\n",
    "            print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7ecb71b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Dict, Optional, Any\n",
    "\n",
    "class AgentMessage(TypedDict):\n",
    "    \"\"\"Represents a structured message from an agent to the shared state.\"\"\"\n",
    "    sender: str\n",
    "    \n",
    "    content: Any\n",
    "    \n",
    "    message_type: str\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"A comprehensive state for a data science pipeline.\"\"\"\n",
    "    run_id: str\n",
    "    requirement: str\n",
    "\n",
    "    raw_data_path: List[str]\n",
    "    \n",
    "    evaluation_results: Optional[Dict[str, float]]\n",
    "    visualization_paths: Optional[List[str]]\n",
    "\n",
    "    agent_messages: List[AgentMessage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b3b28de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphlib import TopologicalSorter, CycleError\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import copy\n",
    "import json \n",
    "\n",
    "class TaskNode:\n",
    "    \"\"\"Represents a single node in the task graph.\"\"\"\n",
    "    def __init__(self, node_id: str, instruction: str, dependencies: list[str], task_type: TaskType, output: str):\n",
    "        if not isinstance(node_id, str) or not node_id:\n",
    "            raise ValueError(\"task_id must be a non-empty string.\")\n",
    "        \n",
    "        self.node_id = node_id\n",
    "        self.instruction = instruction\n",
    "        self.dependencies = dependencies\n",
    "        self.status = TaskStatus.PENDING\n",
    "        self.task_type = task_type\n",
    "        self.output = output\n",
    "        self.result: str | None = None\n",
    "        self.action_graph = ActionGraph()\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Provides a string representation for the task node.\"\"\"\n",
    "        return (f\"TaskNode(id='{self.node_id}', status='{self.status.value}', \"\n",
    "                f\"instruction='{self.instruction[:30]}...', deps={self.dependencies})\")\n",
    "\n",
    "    def generate_action_graph(self, llm: ChatOpenAI, agent_state: GraphState, tool_sets=[], additional_instruction: str = \"\" ) -> ActionGraph:\n",
    "        structured_llm = llm.with_structured_output(PydanticActionGraph)\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"You are a data science code generator. Given a task instruction, break it down into a sequence of executable Python code snippets. Assume pandas is imported as pd and the data is in a DataFrame named 'df'.\"),\n",
    "            (\"human\", \"Generate the action steps for this task: {instruction}. {additional_instruction}. Here is the Agent State where you can find information needed: {agent_state}\")\n",
    "        ])\n",
    "        chain = prompt | structured_llm\n",
    "        \n",
    "        pydantic_action_graph: PydanticActionGraph = chain.invoke({\"instruction\": self.instruction, \"additional_instruction\":additional_instruction, \"agent_state\":agent_state}) # type: ignore\n",
    "        \n",
    "        action_graph = ActionGraph()\n",
    "        for p_node in pydantic_action_graph.task_nodes:\n",
    "            action_node = ActionNode(\n",
    "                action_id=p_node.action_id,\n",
    "                description=p_node.description,\n",
    "                code=p_node.code\n",
    "            )\n",
    "            action_graph.add_action(action_node)\n",
    "        return action_graph\n",
    "\n",
    "    def refine_and_update_action_graph(self, llm: ChatOpenAI, agent_state: GraphState):\n",
    "        refined_graph: ActionGraph = self.generate_action_graph(llm=llm, agent_state=agent_state, additional_instruction=f\"A few errors were encountered when running the actions one-by-one. The current ActionGraph is {str(self.action_graph.nodes)}. You need to debug the code using the error message: {str(self.action_graph.result)}\")\n",
    "        self.action_graph.nodes = refined_graph.nodes\n",
    "        self.action_graph.result = None\n",
    "\n",
    "    def iterate_refining(self, llm: ChatOpenAI, agent_state: GraphState):\n",
    "        \"\"\"Generate and refine the ActionGraph within a trial limit.\"\"\"\n",
    "        current_state: GraphState = copy.deepcopy(agent_state)\n",
    "        \n",
    "        max_retries = 3\n",
    "        action_graph: ActionGraph = self.generate_action_graph(llm=llm, agent_state=current_state)\n",
    "        self.action_graph = action_graph\n",
    "        for _ in range(max_retries):\n",
    "            namespace = {\"agent_state\": current_state}\n",
    "            self.action_graph.execute_action_graph(namespace)\n",
    "            if self.action_graph.result is None:\n",
    "                raise Exception(\"Action Graph Result is None\")\n",
    "            if self.action_graph.result.success is False:\n",
    "                self.refine_and_update_action_graph(llm=llm, agent_state=current_state)\n",
    "            else:\n",
    "                self.status = TaskStatus.SUCCESS\n",
    "                break\n",
    "        if self.action_graph.result is not None and self.action_graph.result.success is False:\n",
    "            self.status = TaskStatus.FAILED\n",
    "            self.result = str(self.action_graph.result)\n",
    "\n",
    "    def run_action_graph(self, agent_state: GraphState) -> GraphState:\n",
    "        namespace = {\"agent_state\": agent_state}\n",
    "        self.action_graph.execute_action_graph(namespace)\n",
    "        if self.action_graph.result and self.action_graph.result.final_state:\n",
    "            return self.action_graph.result.final_state # type: ignore\n",
    "        else:\n",
    "            raise RuntimeError(f'Failed to run ActionGraph {self.node_id}: {self.action_graph.result}')\n",
    "\n",
    "class TaskGraph:\n",
    "    \"\"\"Manages the entire Directed Acyclic Graph (DAG) of tasks.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.nodes: dict[str, TaskNode] = {}\n",
    "\n",
    "    def add_task(self, task: TaskNode, replace: bool = False):\n",
    "        \"\"\"Adds a TaskNode to the graph.\n",
    "        If a task with the same id exists:\n",
    "          - if replace is True, overwrite the existing TaskNode,\n",
    "          - otherwise raise ValueError.\n",
    "        \"\"\"\n",
    "        if not isinstance(task.node_id, str) or not task.node_id:\n",
    "            raise ValueError(\"task_id must be a non-empty string.\")\n",
    "        if task.node_id in self.nodes:\n",
    "            if replace:\n",
    "                self.nodes[task.node_id] = task\n",
    "                print(f\"Replaced existing Task with id '{task.node_id}'.\")\n",
    "                return\n",
    "            raise ValueError(f\"Task with id '{task.node_id}' already exists. Pass replace=True to overwrite.\")\n",
    "        self.nodes[task.node_id] = task\n",
    "\n",
    "    def get_execution_order(self) -> list[str]:\n",
    "        \"\"\"\n",
    "        Determines the execution order of tasks using topological sort.\n",
    "        This is crucial for executing tasks in the correct sequence based on their dependencies.\n",
    "        \"\"\"\n",
    "        graph_representation = {\n",
    "            task_id: node.dependencies for task_id, node in self.nodes.items()\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            ts = TopologicalSorter(graph_representation)\n",
    "            return list(ts.static_order())\n",
    "        except CycleError as e:\n",
    "            print(f\"Error: A cycle was detected in the task graph. Cannot determine execution order. Details: {e}\")\n",
    "            return []\n",
    "\n",
    "    def print_graph(self, verbose: bool = False):\n",
    "        \"\"\"Prints a summary of all tasks and their dependencies.\"\"\"\n",
    "        if not self.nodes:\n",
    "            print(\"Graph is empty.\")\n",
    "            return\n",
    "        \n",
    "        if verbose:\n",
    "            try:\n",
    "                with open(\"code/action-graph-codes\", \"w\", encoding=\"utf-8\") as f:\n",
    "                    for task_id, node in self.nodes.items():\n",
    "                        f.write(f\"--- Task {task_id} ---\\n\")\n",
    "                        f.write(f\"Instruction: {node.instruction}\\n\")\n",
    "                        # if node has an action_graph, write each action's code\n",
    "                        if getattr(node, 'action_graph', None) and node.action_graph.nodes:\n",
    "                            for action in node.action_graph.nodes:\n",
    "                                f.write(f\"# Action {action.action_id}: {action.description}\\n\")\n",
    "                                f.write(action.code + \"\\n\\n\")\n",
    "                        else:\n",
    "                            f.write(\"# No action graph available\\n\\n\")\n",
    "                print(\"Saved action graphs codes to 'action-graph-codes'\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to write action graphs to file: {e}\")\n",
    "        \n",
    "        else:\n",
    "            print(\"--- Task Graph ---\")\n",
    "            for task_id, node in self.nodes.items():\n",
    "                print(f\"  - ID: {task_id}, Status: {node.status.value}\")\n",
    "                print(f\"    Instruction: {node.instruction}\")\n",
    "                print(f\"    Dependencies: {node.dependencies or 'None'}\")\n",
    "            print(\"--------------------\")\n",
    "\n",
    "    def run_workflow(self, agent_state: GraphState, stop_on_failure: bool = True) -> GraphState:\n",
    "        \"\"\"\n",
    "        Run tasks in topological order. For each TaskNode:\n",
    "          - evaluate optional `condition` (simple eval with limited globals),\n",
    "          - execute via TaskNode.iterate_refining(llm, agent_state),\n",
    "          - update agent_state from action_graph result if present.\n",
    "        Returns final agent_state dict.\n",
    "        \"\"\"\n",
    "        # ensure order\n",
    "        order = self.get_execution_order()\n",
    "        if not order:\n",
    "            print(\"No execution order (empty graph or cycle detected).\")\n",
    "            return agent_state\n",
    "\n",
    "        current_state: GraphState = copy.deepcopy(agent_state)\n",
    "\n",
    "        for tid in order:\n",
    "            if tid not in self.nodes:\n",
    "                print(f\"Skipping unknown task id {tid}\")\n",
    "                continue\n",
    "\n",
    "            node = self.nodes[tid]\n",
    "            print(f\"== Running task {tid}\")\n",
    "\n",
    "            try:\n",
    "                current_state = node.run_action_graph(agent_state=current_state)\n",
    "                print(f'Current State: {current_state}')\n",
    "            except Exception as e:\n",
    "                print(f\"Exception when running task {tid}: {type(e).__name__}: {e}\")\n",
    "                node.status = TaskStatus.FAILED\n",
    "                if stop_on_failure:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            if node.status == TaskStatus.FAILED and stop_on_failure:\n",
    "                print(\"Stopping workflow due to failure.\")\n",
    "                break\n",
    "\n",
    "        return current_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3e6c2494",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class PydanticTaskNode(BaseModel):\n",
    "    \"\"\"Schema for task node.\"\"\"\n",
    "    task_id: str = Field(..., description=\"Unique id for the task node in number, e.g. 1, 2, 3 etc\")\n",
    "    dependencies: List[str] = Field(..., description=\"A list of unique ids of nodes must be completed before this.\")\n",
    "    instruction: str = Field(..., description=\"A concise instruction for the task node.\")\n",
    "    task_type: TaskType = Field(description=\"Current status of the task\")\n",
    "    output: str = Field(..., description=\"description of what data or model is produced.\")\n",
    "\n",
    "    # produces: List[str] = Field(default_factory=list, description=\"Named artifacts produced by this task (e.g. cleaned.csv, model.pkl).\")\n",
    "    # consumes: List[str] = Field(default_factory=list, description=\"Named artifacts consumed by this task.\")\n",
    "    # condition: Optional[str] = Field(None, description=\"Optional condition expression (evaluated at runtime) to decide whether to run this task.\")\n",
    "    # parallelizable: bool = Field(True, description=\"Whether this task can be run in parallel with other independent tasks.\")\n",
    "    # retry_policy: Optional[Dict[str, Any]] = Field(None, description=\"Retry policy, e.g. {'max_retries': 3, 'backoff': 'exponential'}\")\n",
    "    \n",
    "class PydanticTaskGraph(BaseModel):\n",
    "    \"\"\"Schema for task graph.\"\"\"\n",
    "    task_nodes: List[PydanticTaskNode] = Field(..., description=\"List of task nodes for the process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fd236009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_task_node(task_graph: TaskGraph) -> TaskNode | None:\n",
    "    \"\"\"\n",
    "    Select a task node with PENDING status from the task graph.\n",
    "    Returns the first pending task found, or None if no pending tasks exist.\n",
    "    \"\"\"\n",
    "    for task in task_graph.nodes.values():\n",
    "        if task == TaskStatus.PENDING:\n",
    "            return task\n",
    "    \n",
    "    return None\n",
    "\n",
    "def is_graph_finished(task_graph: TaskGraph) -> bool:\n",
    "    \"\"\"\n",
    "    Checks if there is any pending nodes in graph.\n",
    "    Returns boolean value to indicate the graph condition.\n",
    "    \"\"\"\n",
    "    for task in task_graph.nodes.values():\n",
    "        if task.status == TaskStatus.PENDING:\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "92e8c68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import json\n",
    "\n",
    "class MasterAgent:\n",
    "    def __init__(self, model:str, tools=[], max_retries:int = 3):\n",
    "\n",
    "        self.max_retries = max_retries\n",
    "        self.llm = ChatOpenAI(\n",
    "            model=model,\n",
    "            temperature=0,\n",
    "            max_completion_tokens=None,\n",
    "            timeout=None,\n",
    "            max_retries=2,\n",
    "          )\n",
    "        \n",
    "        self.tools = tools\n",
    "        self.instructions = '''You are a data science planner. Given a project description, decompose it into a sequence of data science tasks. Respond with a complete graph of all tasks required.\n",
    "The agents are only allowed to access the data in directory '/data' and store or retrieve models in directory '/model'. All the agents will be provided the global AgentState which will store the messages from previous agent\n",
    "All Agent's code should have access to namespace {namespace} and should update their progress to agent_messages, an example will be {sample_agent_message}, where the content field can be any data type.'''\n",
    "        self.task_graph: TaskGraph = TaskGraph()\n",
    "    \n",
    "    def _generate_task_graph(self, human_input:str):\n",
    "        \"\"\"Generates a task graph\"\"\"\n",
    "        structured_llm = self.llm.with_structured_output(PydanticTaskGraph)\n",
    "        state_dict = {'run_id':'1', 'requirement':'data cleaning only', 'raw_data_path':['data/data.csv'], 'agent_messages':[]}\n",
    "        state: GraphState = state_dict  # type: ignore\n",
    "        namespace = {\"agent_state\":state}\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", self.instructions),\n",
    "                (\"human\", \"{input}\"),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        chain = prompt | structured_llm\n",
    "        sample_agent_message: AgentMessage = {'sender':'Data Cleaning Agent', 'content':{\"cleaned_path\": \"/data/cleaned_data.csv\",\"schema\": {\"age\": \"int\", \"salary\": \"float\"},\"summary\": \"Filled 15 missing values in 'salary'. Dropped 1 duplicate row.\"}, 'message_type':'progress update'}\n",
    "        pydantic_response: PydanticTaskGraph = chain.invoke({\"input\": human_input, 'namespace':namespace,'sample_agent_message':sample_agent_message }) # type: ignore\n",
    "        \n",
    "        for pydantic_node in pydantic_response.task_nodes:\n",
    "            node_data = pydantic_node.model_dump()\n",
    "            node = TaskNode(\n",
    "                node_id=node_data[\"task_id\"],\n",
    "                instruction=node_data[\"instruction\"], \n",
    "                dependencies=node_data[\"dependencies\"], \n",
    "                task_type=node_data[\"task_type\"],\n",
    "                output=node_data[\"output\"]\n",
    "            )\n",
    "            self.task_graph.add_task(node)\n",
    "\n",
    "\n",
    "    def _refine_and_update_task_graph(self, add_instructions:str):\n",
    "        raise RuntimeError(f'failed to run Task Graph: {add_instructions}')\n",
    "\n",
    "    def initialize_and_populate_task_graph(self, human_input:str, run_id:str):\n",
    "        state_dict = {'run_id':run_id, 'requirement':human_input, 'raw_data_path':['data/data.csv'], 'agent_messages':[]}\n",
    "        test_state: GraphState = state_dict # type: ignore\n",
    "        self._generate_task_graph(human_input=human_input)\n",
    "        print(f'Task Graph created with {len(self.task_graph.nodes)} Nodes.')\n",
    "        for node in self.task_graph.nodes.values():\n",
    "            print(f'Initializing Node {node.node_id}')\n",
    "            node.iterate_refining(llm=self.llm, agent_state=test_state)\n",
    "            if node.status is TaskStatus.FAILED:\n",
    "                print(f'Iterate refining for Task Node {node.node_id} failed to run in limit {self.max_retries}: {node.action_graph.result}')\n",
    "                self._refine_and_update_task_graph(node.result or '')\n",
    "\n",
    "    def process_requirement(self, human_input:str, run_id:str) -> GraphState:\n",
    "        state_dict = {'run_id':run_id, 'requirement':human_input, 'raw_data_path':['data/data.csv'], 'agent_messages':[]}\n",
    "        state: GraphState = state_dict # type: ignore\n",
    "\n",
    "        for node in self.task_graph.nodes.values():\n",
    "            node.iterate_refining(llm=self.llm, agent_state=state)\n",
    "            if node.status is TaskStatus.FAILED:\n",
    "                raise RuntimeError(f'Error during iteration: {node.action_graph.result}')\n",
    "\n",
    "        final_state = self.task_graph.run_workflow(agent_state=state)\n",
    "        return final_state\n",
    "\n",
    "\n",
    "master_agent = MasterAgent(model=\"gpt-5-mini-2025-08-07\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2b02d806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Graph created with 2 Nodes.\n",
      "Initializing Node 1\n",
      "Initializing Node 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:23: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "<string>:23: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "<string>:23: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "<string>:23: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "<string>:23: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "<string>:23: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "<string>:23: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved action graphs codes to 'action-graph-codes'\n",
      "=== Processing Requirement with Optimized TaskGraph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:20: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "<string>:20: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "<string>:20: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "<string>:20: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "<string>:20: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "<string>:20: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "<string>:20: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "<string>:20: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "<string>:20: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "<string>:20: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "<string>:20: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "<string>:20: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "<string>:20: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Running task 1\n",
      "Current State: {'run_id': '1', 'requirement': '', 'raw_data_path': ['data/data.csv'], 'agent_messages': []}\n",
      "== Running task 2\n",
      "Current State: {'run_id': '1', 'requirement': '', 'raw_data_path': ['data/data.csv'], 'agent_messages': [{'cleaned_path': './cleaned.csv', 'schema': {'Unnamed: 0': 'int64', 'Date': 'object', 'Natural_Gas_Price': 'float64', 'Natural_Gas_Vol.': 'float64', 'Crude_oil_Price': 'float64', 'Crude_oil_Vol.': 'float64', 'Copper_Price': 'float64', 'Copper_Vol.': 'float64', 'Bitcoin_Price': 'object', 'Bitcoin_Vol.': 'float64', 'Platinum_Price': 'float64', 'Platinum_Vol.': 'float64', 'Ethereum_Price': 'object', 'Ethereum_Vol.': 'float64', 'S&P_500_Price': 'object', 'Nasdaq_100_Price': 'object', 'Nasdaq_100_Vol.': 'float64', 'Apple_Price': 'float64', 'Apple_Vol.': 'float64', 'Tesla_Price': 'float64', 'Tesla_Vol.': 'float64', 'Microsoft_Price': 'float64', 'Microsoft_Vol.': 'float64', 'Silver_Price': 'float64', 'Silver_Vol.': 'float64', 'Google_Price': 'float64', 'Google_Vol.': 'float64', 'Nvidia_Price': 'float64', 'Nvidia_Vol.': 'float64', 'Berkshire_Price': 'object', 'Berkshire_Vol.': 'float64', 'Netflix_Price': 'float64', 'Netflix_Vol.': 'float64', 'Amazon_Price': 'float64', 'Amazon_Vol.': 'float64', 'Meta_Price': 'float64', 'Meta_Vol.': 'float64', 'Gold_Price': 'object', 'Gold_Vol.': 'float64'}, 'summary': {'rows': 1243, 'columns': 39, 'duplicates_dropped': 0, 'conversions': {'Platinum_Price': 'to_numeric'}, 'missing_handling': {'Unnamed: 0': {'action': 'filled_median', 'median': 621.0, 'missing_fraction': 0.0}, 'Date': {'action': 'filled_mode', 'mode': '01-02-2021', 'missing_fraction': 0.0}, 'Natural_Gas_Price': {'action': 'filled_median', 'median': 2.702, 'missing_fraction': 0.0}, 'Natural_Gas_Vol.': {'action': 'filled_median', 'median': 127370.0, 'missing_fraction': 0.003218020917135961}, 'Crude_oil_Price': {'action': 'filled_median', 'median': 69.23, 'missing_fraction': 0.0}, 'Crude_oil_Vol.': {'action': 'filled_median', 'median': 366885.0, 'missing_fraction': 0.01850362027353178}, 'Copper_Price': {'action': 'filled_median', 'median': 3.666, 'missing_fraction': 0.0}, 'Copper_Vol.': {'action': 'filled_median', 'median': 10180.0, 'missing_fraction': 0.029766693483507644}, 'Bitcoin_Price': {'action': 'filled_mode', 'mode': '21,365.20', 'missing_fraction': 0.0}, 'Bitcoin_Vol.': {'action': 'filled_median', 'median': 215310.0, 'missing_fraction': 0.0}, 'Platinum_Price': {'action': 'filled_median', 'median': 909.9, 'missing_fraction': 0.3041029766693483}, 'Platinum_Vol.': {'action': 'filled_median', 'median': 6070.0, 'missing_fraction': 0.4883346741753821}, 'Ethereum_Price': {'action': 'filled_mode', 'mode': '1,818.07', 'missing_fraction': 0.0}, 'Ethereum_Vol.': {'action': 'filled_median', 'median': 1570000.0, 'missing_fraction': 0.0}, 'S&P_500_Price': {'action': 'filled_mode', 'mode': '2,926.46', 'missing_fraction': 0.0}, 'Nasdaq_100_Price': {'action': 'filled_mode', 'mode': '10,002.70', 'missing_fraction': 0.0}, 'Nasdaq_100_Vol.': {'action': 'filled_median', 'median': 211620000.0, 'missing_fraction': 0.0008045052292839903}, 'Apple_Price': {'action': 'filled_median', 'median': 136.76, 'missing_fraction': 0.0}, 'Apple_Vol.': {'action': 'filled_median', 'median': 87490000.0, 'missing_fraction': 0.0}, 'Tesla_Price': {'action': 'filled_median', 'median': 202.07, 'missing_fraction': 0.0}, 'Tesla_Vol.': {'action': 'filled_median', 'median': 109520000.0, 'missing_fraction': 0.0}, 'Microsoft_Price': {'action': 'filled_median', 'median': 245.38, 'missing_fraction': 0.0}, 'Microsoft_Vol.': {'action': 'filled_median', 'median': 26100000.0, 'missing_fraction': 0.0}, 'Silver_Price': {'action': 'filled_median', 'median': 22.758, 'missing_fraction': 0.0}, 'Silver_Vol.': {'action': 'filled_median', 'median': 62940.0, 'missing_fraction': 0.03781174577634755}, 'Google_Price': {'action': 'filled_median', 'median': 101.24, 'missing_fraction': 0.0}, 'Google_Vol.': {'action': 'filled_median', 'median': 29730000.0, 'missing_fraction': 0.0}, 'Nvidia_Price': {'action': 'filled_median', 'median': 151.59, 'missing_fraction': 0.0}, 'Nvidia_Vol.': {'action': 'filled_median', 'median': 42790000.0, 'missing_fraction': 0.0}, 'Berkshire_Price': {'action': 'filled_mode', 'mode': '2,72,000', 'missing_fraction': 0.0}, 'Berkshire_Vol.': {'action': 'filled_median', 'median': 1510.0, 'missing_fraction': 0.0}, 'Netflix_Price': {'action': 'filled_median', 'median': 384.15, 'missing_fraction': 0.0}, 'Netflix_Vol.': {'action': 'filled_median', 'median': 5610000.0, 'missing_fraction': 0.0}, 'Amazon_Price': {'action': 'filled_median', 'median': 128.73, 'missing_fraction': 0.0}, 'Amazon_Vol.': {'action': 'filled_median', 'median': 65200000.0, 'missing_fraction': 0.0}, 'Meta_Price': {'action': 'filled_median', 'median': 224.43, 'missing_fraction': 0.0}, 'Meta_Vol.': {'action': 'filled_median', 'median': 19340000.0, 'missing_fraction': 0.0}, 'Gold_Price': {'action': 'filled_mode', 'mode': '1,929.50', 'missing_fraction': 0.0}, 'Gold_Vol.': {'action': 'filled_median', 'median': 197970.0, 'missing_fraction': 0.0016090104585679806}}}, 'name': 'cleaned'}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "<string>:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "<string>:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "<string>:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "<string>:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "<string>:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "<string>:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "<string>:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "<string>:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "<string>:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "<string>:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "<string>:21: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "<string>:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n"
     ]
    }
   ],
   "source": [
    "human_request = \"I need to clean up this data. Make the task short with maximum 2 Nodes and each node should have instruction to generate only small ActionGraph with at most 3 Nodes. store the cleaned data with name 'cleaned'\"\n",
    "\n",
    "master_agent.initialize_and_populate_task_graph(human_input=human_request, run_id='1')\n",
    "master_agent.task_graph.print_graph(verbose=True)\n",
    "print('=== Processing Requirement with Optimized TaskGraph')\n",
    "\n",
    "final_state = master_agent.process_requirement(human_input='', run_id='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10fe55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_agent_state_to_json(agent_state: GraphState, filepath: str, ensure_dir: bool = True, indent: int = 2) -> None:\n",
    "    \"\"\"\n",
    "    Write agent_state (GraphState or plain dict) to a JSON file.\n",
    "    Non-serializable values are converted via str().\n",
    "    \"\"\"\n",
    "    import json, os, copy\n",
    "\n",
    "    state_copy = copy.deepcopy(agent_state)\n",
    "\n",
    "    if ensure_dir:\n",
    "        dirpath = os.path.dirname(filepath) or \".\"\n",
    "        os.makedirs(dirpath, exist_ok=True)\n",
    "\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(state_copy, f, ensure_ascii=False, indent=indent, default=str)\n",
    "\n",
    "write_agent_state_to_json(final_state, \"state/agent-state.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113255f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "state_dict = {'run_id':'1', 'requirement':'data cleaning only', 'raw_data_path':['data/data.csv'], 'agent_messages':[]}\n",
    "state: GraphState = state_dict # type: ignore\n",
    "llm = ChatOpenAI(\n",
    "            model=\"gpt-5-mini-2025-08-07\",\n",
    "            temperature=0,\n",
    "            max_completion_tokens=None,\n",
    "            timeout=None,\n",
    "            max_retries=2,\n",
    "          )\n",
    "\n",
    "sample_agent_message: AgentMessage = {'sender':'Data Cleaning Agent', 'content':{\"cleaned_path\": \"/data/cleaned_data.csv\",\"schema\": {\"age\": \"int\", \"salary\": \"float\"},\"summary\": \"Filled 15 missing values in 'salary'. Dropped 1 duplicate row.\"}, 'message_type':'progress update'}\n",
    "namespace = {\"agent_state\":state}\n",
    "instruction=f\"Perform data cleaning: fill missing age values with the median age and drop the 'cabin' column. Save the cleaned data as cleaned_data.csv. You will have access to the universal AgentState {json.dumps(state)}. Save the path to result in the AgentState for others to access. Your code should have access to namespace {namespace} and should update your progress to agent_messages, an example will be {sample_agent_message}, where the content field can be any data type.\"\n",
    "my_task = TaskNode(\n",
    "    node_id=\"2\",\n",
    "    instruction=instruction,\n",
    "    dependencies=[\"1\"],\n",
    "    task_type=TaskType.EXPLORATION,\n",
    "    output=\"cleaned dataframe\"\n",
    ")\n",
    "\n",
    "my_task.iterate_refining(llm=llm, agent_state=state)\n",
    "current_state = my_task.run_action_graph(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "508a9c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActionGraph with 5 actions."
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_task.action_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a149c305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'run_id': '1',\n",
       " 'requirement': 'data cleaning only',\n",
       " 'raw_data_path': ['data/data.csv'],\n",
       " 'agent_messages': [{'sender': 'Data Cleaning Agent',\n",
       "   'content': {'cleaned_path': 'cleaned_data.csv',\n",
       "    'schema': {'Unnamed: 0': 'int64',\n",
       "     'Date': 'object',\n",
       "     'Natural_Gas_Price': 'float64',\n",
       "     'Natural_Gas_Vol.': 'float64',\n",
       "     'Crude_oil_Price': 'float64',\n",
       "     'Crude_oil_Vol.': 'float64',\n",
       "     'Copper_Price': 'float64',\n",
       "     'Copper_Vol.': 'float64',\n",
       "     'Bitcoin_Price': 'object',\n",
       "     'Bitcoin_Vol.': 'float64',\n",
       "     'Platinum_Price': 'object',\n",
       "     'Platinum_Vol.': 'float64',\n",
       "     'Ethereum_Price': 'object',\n",
       "     'Ethereum_Vol.': 'float64',\n",
       "     'S&P_500_Price': 'object',\n",
       "     'Nasdaq_100_Price': 'object',\n",
       "     'Nasdaq_100_Vol.': 'float64',\n",
       "     'Apple_Price': 'float64',\n",
       "     'Apple_Vol.': 'float64',\n",
       "     'Tesla_Price': 'float64',\n",
       "     'Tesla_Vol.': 'float64',\n",
       "     'Microsoft_Price': 'float64',\n",
       "     'Microsoft_Vol.': 'float64',\n",
       "     'Silver_Price': 'float64',\n",
       "     'Silver_Vol.': 'float64',\n",
       "     'Google_Price': 'float64',\n",
       "     'Google_Vol.': 'float64',\n",
       "     'Nvidia_Price': 'float64',\n",
       "     'Nvidia_Vol.': 'float64',\n",
       "     'Berkshire_Price': 'object',\n",
       "     'Berkshire_Vol.': 'float64',\n",
       "     'Netflix_Price': 'float64',\n",
       "     'Netflix_Vol.': 'float64',\n",
       "     'Amazon_Price': 'float64',\n",
       "     'Amazon_Vol.': 'float64',\n",
       "     'Meta_Price': 'float64',\n",
       "     'Meta_Vol.': 'float64',\n",
       "     'Gold_Price': 'object',\n",
       "     'Gold_Vol.': 'float64'},\n",
       "    'summary': \"Filled 0 missing values in 'age'. Dropped 0 'cabin' column.\"},\n",
       "   'message_type': 'progress update'}]}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847bbd75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
